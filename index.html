<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Face blur</title>
    <style>
        button {
            border: solid;
            margin: 15px 32px;
            width: 150px;
            text-align: center;
            display: block;
            font-size: 16px;
        }

        #screen {
            border: solid;
            position: relative;
        }

        #screen


    </style>
    <!-- Import @tensorflow/tfjs or @tensorflow/tfjs-core -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu/dist/tf-backend-webgpu.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
    <script>
        async function init() {
            let backend = document.getElementById('backend').value;
            await tf.setBackend(backend);
        }

        function waitFor(delay_ms) {
          return new Promise((resolve, _) => {
            setTimeout(resolve, delay_ms);
          });
        }

        function createDecodedStream(dataUri) {
            const decoder_worker = new Worker("./decoder_worker.js");
            const ready_frames = [];
            let next_frame_ready_callback = null;
            function onFrame(frame) {
                if (!frame) {
                    decoder_worker.terminate();
                }
                if (next_frame_ready_callback) {
                    next_frame_ready_callback(frame);
                    next_frame_ready_callback = null;
                }
                else
                    ready_frames.push(frame);
            }
            decoder_worker.addEventListener("message", message => onFrame(message.data));
            decoder_worker.postMessage({dataUri});

            async function getNextFrame() {
                if (ready_frames.length > 0)
                    return ready_frames.shift();

                let next_frame_promise = new Promise((resolve, reject) => {
                    next_frame_ready_callback = resolve;
                });
                return next_frame_promise;
            }
            return getNextFrame;
        }

        function createFrameConverter() {
            const converter_worker = new Worker("./face_detection.js");
            const ready_frames = [];
            let next_frame_ready_callback = null;
            function onFrame(frame) {
                if (!frame) {
                    converter_worker.terminate();
                }
                if (next_frame_ready_callback) {
                    next_frame_ready_callback(frame);
                    next_frame_ready_callback = null;
                }
                else
                    ready_frames.push(frame);
            }
            converter_worker.addEventListener("message", message => onFrame(message.data));

            async function getNextFrame(frame) {
                converter_worker.postMessage(frame, [frame]);
                if (ready_frames.length > 0)
                    return ready_frames.shift();

                let next_frame_promise = new Promise((resolve, reject) => {
                    next_frame_ready_callback = resolve;
                });
                return next_frame_promise;
            }
            return getNextFrame;
        }

        async function getCameraInputReader(constraints) {
            const stream = await window.navigator.mediaDevices.getUserMedia(constraints);
            const track = stream.getTracks()[0];
            const media_processor = new MediaStreamTrackProcessor(track);
            const reader = media_processor.readable.getReader();
            async function getNextFrame() {
                const { done, value } = await reader.read();
                if (done) {
                    return null;
                }
                const frame = value;
                return frame;
            }
            return getNextFrame;
        }

        async function main() {
            await init();
            const width = 1280;
            const height = 720;

            const desired_fps = 60;
            const constraints = { audio: false, video:  { width: width, height: height, frameRate: desired_fps } };
            const screen = document.querySelector('#screen');
            screen.width = width;
            screen.height = height;
            const ctx = screen.getContext('2d', {alpha : false});

            const offscreen = new OffscreenCanvas(width, height);
            const offscreen_ctx = offscreen.getContext('2d', {willReadFrequently : false});

            const model = faceDetection.SupportedModels.MediaPipeFaceDetector;
            const detectorConfig = {
                runtime: 'tfjs',
                //modelType: 'short',
                modelType: 'full',
                maxFaces: 7,
            };
            const detector = await faceDetection.createDetector(model, detectorConfig);

            //let frameReader = await getCameraInputReader(constraints);
            let frameReader = createDecodedStream('./friends.mp4');
            let start_time = performance.now();
            let frame_counter = 0;
            while (true) {
                let frame = await frameReader();
                if (!frame) {
                    break;
                }
                frame_counter++;
                offscreen_ctx.drawImage(frame, 0, 0);

                const faces = await detector.estimateFaces(offscreen);
                ctx.drawImage(offscreen, 0, 0);
                for (let face of faces) {
                    const box = face.box;
                    const safety_margin = box.width / 10;
                    box.xMin -= safety_margin;
                    box.yMin -= safety_margin;
                    box.width += 2 * safety_margin;
                    box.height += 2 * safety_margin;

                    ctx.fillRect(box.xMin, box.yMin, box.width, box.height);

                }
                frame.close();
            }
            let end_time = performance.now();

            let label = document.createElement('pre');
            document.body.appendChild(label);
            label.innerText = `FPS: ${frame_counter / (end_time - start_time) * 1000}`;

        }
    </script>

</head>

<body>
    <div>
        <select id="backend">
          <option value="webgpu" selected>webgpu</option>
          <option value="webgl">webgl</option>
          <option value="wasm">wasm</option>
        </select>
        <button onclick="main()">Start</button>
        <canvas id='screen'></canvas>
    </div>
</body>

</html>